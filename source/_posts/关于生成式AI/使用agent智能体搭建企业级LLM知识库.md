# 场景落地：使用agent搭建企业级知识库

## 前言

​	人工智能学科诞生于20世纪50年代，早在其还是萌芽阶段的时候，人工智能的大牛们就不断尝试让人工智能理解人类知识，并对人类的语言做出类似人类的反馈的超级梦想。

​	而早期的实现方案比较原始，使用了通用问题解决器（General Problem Solver），也被称为专家系统的技术方案进行解决。

​	专家系统本质上就是录入问题与答案，当用户问问题的时候，将匹配到的答案呈现给用户。

​	大家想象一下5年前的车机系统，其语音功能只能针对一些特定意思的简单的短句做出反馈，稍微复杂一点，或者超出了车机知识的范畴，专家系统便无法正常工作，这样的反应，只能被认为是人工智障。

​	以开车场景下驾驶员对车机说“风有点大，帮我关闭窗户”作为例子，车机也许够做出适当的反馈，甚至你只需要说“风有点大”，车机就能明白需要进行“关窗”这样的行为；

​	虽然车机做出了我们预期的反馈，但是车机其实并不懂得这句话的意思，也并不理解力说的“冷”的含义。

​	车机的理解更加像是文字与行为的匹配、关键字的匹配，进而完成相应的操作，至于文字究竟是什么意思，车机完全不明白；

​	如果我们想让这样的车机达到我们预期的“人工智能”，其背后我们则需要输入无数这样的文字与行为的匹配，让他按照字典的方式去对人类的行为进行反馈；即使这样的车机拥有海量的字典知识，让绝大部分人都无法第一时间感觉到“机械感”，但是稍微复杂的问题，即便会露馅，更别提类似人类的操作了，这远远不是我们期望的人工智能。



## 大语言模型开启真正的AI知识库

​	大语言模型依托于海量知识，天生对语言具备接近人类的理解能力，但是大语言模型在训练阶段其得到的知识大多都不是特别具有深度的内容，更别提一些特定行业、公司内部的知识，如何将公司内部的文档交给大语言模型并充分发挥大语言模型的能力，实现知识库问答呢？

### RAG

​	在大语言模型时代，我们拥有了杀手级的工具来实现针对大语言模型的知识补充；

​	RAG，全称是Retrieval Augmented Generation，中文含义为检索增强生成。

​	这个工具的实现流程是什么样呢？

1. 数据准备阶段
   1. 上传知识库
   2. 将文本按照期待的格式进行分割
   3. 使用embedding技术，将文字向量化，让AI理解我们的知识库
   4. 存储我们的向量数据
2. 提问阶段
   1. 用户提问
   2. 理解用户的问题，并召回相关文字片段
   3. 大模型结合问题 + 答案进行理解，并回答用户的问题

![](http://qiliu.vkcyan.top/Fhjx146fU0dKRX2qHdv7_zkoEH78.png)



### 使用coze进行实现

理论存在，实践开始！

具体的实现，我们使用国内非常领先的由字节跳动公司推出的coze作为生成式AI使用软件

https://www.coze.cn/home









## 什么是agent智能体？



## 使用agent智能体搭建企业级知识库

