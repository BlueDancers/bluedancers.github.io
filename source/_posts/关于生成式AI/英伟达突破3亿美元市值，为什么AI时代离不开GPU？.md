# 英伟达突破3亿美元市值，为什么AI时代离不开GPU？



## 前言

​	2024年6月上旬，英伟达市值超过3万亿美元，尽管后续跌了1.18%，市值又回到了3万亿美元以下，但是这依旧没有冷却人们内心对英伟达的狂热，过去五年，英伟达的市值已经增长了3200%，但是无数人依旧相信，英伟达还存在增长前景。

​	而现在的英伟达已经做到**我要打十个**的状态，实际上在写这篇文章的今天，英伟达的市值已经到了3.34万亿美元，一天的交易日的涨跌都超过IBM的总市值。

​	**假如在2019年，某人购买了10万元的英伟达股票，现在他将可以收获340+万元。**

​	借用2024年5月22日的市值对比图，实际上现在更多了。

<img src="http://qiliu.vkcyan.top/Fr1dTwKxpnc4LO8fkoGg1Xl9dQ-1.png" style="zoom: 33%;" />

​	为什么英伟达的市值可以达到如此"恐怖"的高度，一方面肯定是英伟达的技术硬实力，在GPU领域的深耕，另外是英伟达非常善于利用自身优势，构思在竞争对手前面，提前布局未来需求，这几年无独有偶的总是赶上了一系列算力的风口，比特币、元宇宙、大模型人工智能、智能驾驶、人形机器人。

​	英伟达早已不是以前“玩物丧志”的游戏显卡生意，在 AI 服务器核心芯片（GPU）领域，英伟达占据了近乎 80%的收入份额。其展现出的市场统治力令人惊叹，几乎完美复刻了英特尔鼎盛时期在 PC 市场上对 CPU 的市占率表现。而GPU的各大买家，还在催着要英伟达的货，就差把拉货的飞机停在代工厂台积电的门口。

​	聊了这么多，也算是进入今天的正题了，为什么在AI大模型时代，高算力的GPU如此的稀缺？为了搞明白这个问题，我们首先要搞清楚GPU和CPU的区别？



## CPU和GPU的区别

​	在我早些年接触加密货币的时候，我听说，加密货币需要算力，算力需要显卡的支持，我当时就纳闷了，**为什么算力问题通过显卡而不是电脑的核心处理器呢？**

​	从运算能力的角度来说，肯定是中央处理器的运算能力更强才对；当我弄清楚CPU和GPU的区别，还有挖矿的具体逻辑的时候，我理解了为什么加密货币需要显卡来完成。

 **CPU**（中央处理器）

- **通用性**：CPU设计用于处理各种类型的任务，从操作系统的管理到复杂应用程序的执行。它们的架构使得它们可以高效地处理几乎所有类型的计算任务。
- **核心数量**：现代的CPU通常有2到16个核心（高端服务器可能更多），并且每个核心都非常强大。
- **时钟速度**：CPU的时钟速度（频率）通常较高，可以执行复杂的指令。

<img src="http://qiliu.vkcyan.top/Fu_BuZAztNg-pGWb17AYu0g2RbkP.png" style="zoom: 67%;" />

**GPU**（图形处理器）

- **专用性**：GPU最初是为图形处理和图像渲染设计的，尤其是需要并行处理的任务。
- **核心数量**：GPU拥有大量的核心，典型的GPU可以有几千个核心，但每个核心的单线程性能不如CPU核心。
- **并行处理**：GPU的架构非常适合处理大量的并行计算任务。它们可以同时处理成千上万的线程，这是它们在图形渲染和科学计算中表现出色的原因。

<img src="http://qiliu.vkcyan.top/Fi_ElbrPn5rVEn8M_1OS5ay6oB89.png" style="zoom:33%;" />



### 类比一下

​	上面的专业对比似乎并不好理解，我们换一种更加通俗的方式去解释：

​	**CPU就像一个20人一下的教授团队**，每个核心都是一个教授，某些特别复杂的问题只有教授才能胜任。因此，教授在处理复杂单一任务时非常出色，适用于需要高技能和复杂思考的任务，如高级算法计算、复杂数据分析等。

​	**GPU更像一大群高中生**，虽然单个高中生的能力不及教授，但他们可以同时处理许多简单的任务，因此在处理大量简单任务时效率极高，适用于需要大量重复和并行处理的任务，如图像渲染、加密货币挖矿中的哈希计算。



### 加密货币的计算特征

​	了解了GPU与GPU的区别后，我又去了解了机密货币的一些逻辑，总算是可以清晰的解释，为什么挖矿使用GPU了。

​	加密货币挖矿中的一个关键任务是解决哈希函数（如SHA-256）的问题；

​	具体来说是什么呢，在比特币挖矿中，矿工的任务是找到一个特定的哈希值，该哈希值必须满足一定的条件，这个过程被称为“Proof of Work”（工作量证明），而“计算哈希值”，这是一个非常耗时的过程，需要大量的计算。

​	为了找到符合条件的哈希值，矿工需要尝试大量的运算，这些尝试是完全独立的，可以同时进行，这就代表些运算是独立的，可以同时进行。

​	这样的场景化GPU的计算优势就发挥出来了，虽然单个GPU核心的运算速度不如CPU核心，但由于并行处理的优势，整体性能会比CPU高得多；一个GPU有成千上万个小核心，可以同时处理成千上万个哈希计算任务。相比之下，CPU的核心数量少得多，无法提供如此高的并行计算能力。

​	简而言之，加密货币挖矿依赖于大量的哈希计算，而这些计算任务**可以被分解成许多独立的小任务，因此非常适合GPU的大规模并行处理能力。**



## 为什么AI时代离不开使用GPU？

​	其实通过上面的案例，我们也需要明白一点，**显卡不仅仅是用来打游戏**，只不过3D游戏的渲染需要GPU的并行计算能力，同时，过去几十年的GPU主要被用在显卡这个领域，所以我们将自然而然的认为GPU = 显卡，甚至出现了错误的理解，显卡就是用来玩游戏的。

​	实际上，GPU生来就是为了大规模并行计算。

​	现在我们回到文章的核心主题，为什么类似chatGPT的技术离不开GPU，为什么不用更加聪明的CPU呢？

### 大模型的本质是模拟人脑的神经网络

​	首先我们需要知道一点，大模型本质上是一个复杂的数学模型，用来模拟人脑的工作方式，这个模型由许多“神经元”组成，这些神经元分布在不同的“层”中。

​	每一层神经元都与下一层神经元相连，形成一个网络。

​	训练神经网络的过程就像教学生读书写字。我们给网络大量的数据（例如图片、文字、声音等），让它们自行“学习”如何识别、理解或处理这些数据。

### 训练神经网络

​	大模型是如何完成对文字的理解的呢？

​	首先，我们需要文本数据被转换成数字表示，这些数字我们称之为**向量**，大家可以理解为坐标。

> 为了方便大家理解，这里采用B站Up主「新石器公园」的相关视频截图

<img src="http://qiliu.vkcyan.top/FnFpMUAGU2VuVX9XqTznrVX9KnDh.png" style="zoom:25%;" />

​	大模型会在一个空间内不断根据投喂知识调整每个字的坐标，每次调整的时候，都需要针对关联的文字的向量进行计算，这部分的计算量是极其庞大的；

### 通过GPU实现并行计算

​	为了完成这些计算，大模型会利用成千上万个计算核心，也就是GPU，同时对不同文字的坐标进行调整。这种同时进行很多计算任务的方式叫做**并行计算**。

​	因为有大量的计算核心一起工作，大模型可以很快地处理这些庞大的计算任务。

​	随着吸收的知识越来越多，大模型也对文字的理解也会越来越正确，就像国王与王后这2个词非常接近。

<img src="http://qiliu.vkcyan.top/FnD4RoobiPHIEc4K5LFcEtIOxZZo.png" style="zoom:25%;" />

​	最终大模型将会形成一个类似人脑结构，并且像人类一样理解字与字、词与词之间的联系，对事物的正确理解，最终让模型学习如何生成有意义的文章。

<img src="http://qiliu.vkcyan.top/FhtUtp3WG_-Mducq9ngZmJSwXn4-.png" style="zoom:25%;" />



### 使用CPU行不行？

​	理论上可以，实际没人会这么干，我们上面分析过CPU，类比来说，CPU是一群教授，但是我们的大模型训练阶段，需要大量的难度不大，但是数量很大的计算；

​	当我们使用GPU的集群训练类似GPT-3级别的大模型可能需要2周，甚至更短，如果使用CPU进行训练则需要几个月甚至更长时间，这几乎就不存在可行性了。

​	总体来说，使用GPU训练大模型的时间通常比使用CPU短一个数量级以上，也就是说通常可以节省10倍甚至更多的时间。



​	

